"""
Create a HuggingFace Collection containing all 18 FinSent-CoT model repos.

Creates one collection with all 6 models √ó 3 quantizations (Q4_K_M, Q5_K_M, Q8_0),
plus the dataset repo. Similar to Qwen's model collections on HuggingFace.

Usage:
    python training/create_hf_collection.py
    python training/create_hf_collection.py --dry-run    # Preview without creating
"""

import argparse
from huggingface_hub import HfApi, create_collection, add_collection_item

from model_configs import MODEL_CONFIGS, MODEL_ORDER, QUANTIZATIONS


COLLECTION_TITLE = "FinSent-CoT"
COLLECTION_DESCRIPTION = (
    "Financial Sentiment Analysis with Chain-of-Thought Reasoning.\n\n"
    "6 fine-tuned models (Qwen3-0.6B, Qwen3-1.7B, Qwen3-4B, Qwen3-8B, "
    "DeepSeek-R1-Distill-1.5B, MobileLLM-R1-950M) each exported in 3 GGUF "
    "quantizations (Q4_K_M, Q5_K_M, Q8_0) for deployment via Ollama/llama.cpp.\n\n"
    "Pipeline: CoT data generated by Qwen3-235B-A22B ‚Üí SFT warm-up ‚Üí GRPO "
    "with 4 reward functions (correctness, format, reasoning quality, consistency) "
    "‚Üí GGUF export.\n\n"
    "Trained on IU Big Red 200 (Hopper H100 GPUs)."
)

DATASET_REPO = "Ayansk11/FinSent-CoT-Dataset"


def main():
    parser = argparse.ArgumentParser(description="Create HuggingFace Collection for FinSent-CoT")
    parser.add_argument("--dry-run", action="store_true",
                        help="Preview repos without creating collection")
    args = parser.parse_args()

    # Build the ordered list of all repos to add
    repos = []

    # Add dataset first
    repos.append({
        "item_id": DATASET_REPO,
        "item_type": "dataset",
        "note": "CoT training dataset ‚Äî 4.7K balanced 3-class financial sentiment",
    })

    # Add models grouped by model name, then by quantization
    for model_key in MODEL_ORDER:
        config = MODEL_CONFIGS[model_key]
        hf_repos = config["hf_repos"]
        short_name = config["short_name"]
        family = config["model_family"]
        backend = "Unsloth QLoRA" if config["use_unsloth"] else "PEFT + bitsandbytes"

        for quant in QUANTIZATIONS:
            repo_id = hf_repos[quant]
            note = f"{short_name} ‚Äî {quant} quantization ({backend})"
            if quant == "Q5_K_M":
                note += " ‚≠ê Recommended"
            repos.append({
                "item_id": repo_id,
                "item_type": "model",
                "note": note,
            })

    # Preview
    print(f"Collection: {COLLECTION_TITLE}")
    print(f"Total items: {len(repos)} (1 dataset + 18 models)")
    print()
    for i, repo in enumerate(repos, 1):
        icon = "üìä" if repo["item_type"] == "dataset" else "ü§ñ"
        print(f"  {i:2d}. {icon} {repo['item_id']}")
        print(f"      {repo['note']}")
    print()

    if args.dry_run:
        print("DRY RUN ‚Äî no collection created.")
        return

    # Create collection
    api = HfApi()

    print("Creating collection...")
    collection = create_collection(
        title=COLLECTION_TITLE,
        description=COLLECTION_DESCRIPTION,
        namespace="Ayansk11",
        private=False,
    )
    print(f"Collection created: {collection.slug}")
    print(f"URL: https://huggingface.co/collections/{collection.slug}")

    # Add all items
    print(f"\nAdding {len(repos)} items...")
    for repo in repos:
        try:
            add_collection_item(
                collection_slug=collection.slug,
                item_id=repo["item_id"],
                item_type=repo["item_type"],
                note=repo["note"],
            )
            print(f"  ‚úì {repo['item_id']}")
        except Exception as e:
            print(f"  ‚úó {repo['item_id']} ‚Äî {e}")

    print(f"\nDone! Collection URL: https://huggingface.co/collections/{collection.slug}")


if __name__ == "__main__":
    main()
